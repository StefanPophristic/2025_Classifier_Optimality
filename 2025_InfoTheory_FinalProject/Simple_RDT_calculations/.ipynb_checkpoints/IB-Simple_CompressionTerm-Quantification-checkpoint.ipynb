{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56ef5920-5026-4b89-9779-c12ad01dda64",
   "metadata": {},
   "source": [
    "Stefan Pophristic + Boxuan Li\n",
    "May 1st, 2025\n",
    "Information Theory Project\n",
    "\n",
    "After our Meeting with Noga on April 30th, we agreed to first try to implement a simpler information bottlneck calcuation to test whether Mandarin classifiers are optimal. \n",
    "\n",
    "The general IB Formula is:\n",
    "$$\n",
    "  min I(X;T) - \\beta I(T;Y)\n",
    "$$\n",
    "\n",
    "Noga suggested the quantify our analysis as follows:\n",
    "$$\n",
    "I_{q}(N;W) + \\beta \\mathbb{E}[d(N; N_{w})]\n",
    "$$\n",
    "\n",
    "N = the set of all Nouns to which MW can refer to\n",
    "W = the set of all MW\n",
    "\n",
    "\n",
    "**In this script we quantify the first term**\n",
    "\n",
    "**The First Term (Input Term)**\n",
    "The mutual information between N and W can be computed using the normal mutual information calculations:\n",
    "$$\n",
    "I_{q}(N;W) = \\sum_{n\\in N}\\sum_{w \\in W} p(n,w) log\\frac{p(n,w)}{p(n)p(w)}\n",
    "$$\n",
    "$$\n",
    "p(n, w) = p(n|w)p(w)\n",
    "$$\n",
    "\n",
    "p(n) = probbability of a noun in the corpus\n",
    "p(w) = probability of a MW in the corpus\n",
    "p(n|w) = probability of the noun given a MW\n",
    "\n",
    "\n",
    "**The Second Term (Output Term)**\n",
    "Also known as the reconstruction error. \n",
    "\n",
    "$N_{w}$ = The set of centroids in the semantic vector space of all nouns, grouped by MW\n",
    "\n",
    "$d$ is a function that measures the reconstruction error. It could be something like KL divergence or mean square errors. In our case, we will just use the cosine similarity (i.e. distance in semantic vector space) between an N and its associated MW. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9dbc90-e0e0-4678-b8a6-e79e8814402d",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d49d1c-5ee7-4aa1-8b94-3a6a0adc73d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For displaying Chinese characters properly\n",
    "plt.rcParams['font.family'] = ['Arial Unicode MS', 'SimHei', 'sans-serif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce64cc94-6909-4bf5-a3f0-60e082ee9f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MW and Noun combinations from the corpus\n",
    "\n",
    "df = pd.read_csv(\"../chinese_noun_mw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d09397b-b7bf-4abc-8a85-1ec380e85d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Noun</th>\n",
       "      <th>MW</th>\n",
       "      <th>Count_Pre</th>\n",
       "      <th>Count_Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>上午</td>\n",
       "      <td>日</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>下半</td>\n",
       "      <td>局</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>下旬</td>\n",
       "      <td>年</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>下旬</td>\n",
       "      <td>月</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>下颌</td>\n",
       "      <td>个</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Noun MW  Count_Pre  Count_Post\n",
       "0   上午  日          1           0\n",
       "1   下半  局          1           0\n",
       "2   下旬  年          1           0\n",
       "3   下旬  月          2           0\n",
       "4   下颌  个          1           0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd8c02db-83cd-4957-b828-273a333f3dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of MW + Noun tokens: 2289\n",
      "Total number of unique MW: 110\n",
      "Total number of unique Nouns: 847\n"
     ]
    }
   ],
   "source": [
    "token_count = df[\"Count_Pre\"].sum()\n",
    "print(f\"Total number of MW + Noun tokens: {token_count}\")\n",
    "\n",
    "MW_count = df[\"MW\"].nunique()\n",
    "print(f\"Total number of unique MW: {MW_count}\")\n",
    "\n",
    "N_count = df[\"Noun\"].nunique()\n",
    "print(f\"Total number of unique Nouns: {N_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d3b669-d7d7-4104-8d7b-092ed63f6e0d",
   "metadata": {},
   "source": [
    "# Quantify Probabilities [p(n), p(w), p(n|w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a054238-20fc-4e5e-82f6-d7508edbc7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save dataframe with all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "827a5cba-685d-476f-b34c-21a9f00d38a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Noun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>上午</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>下半</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>下旬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>下旬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>下颌</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Noun\n",
       "0   上午\n",
       "1   下半\n",
       "2   下旬\n",
       "3   下旬\n",
       "4   下颌"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate p(n) for all n\n",
    "\n",
    "# Create dataframe with all N\n",
    "df_N = pd.DataFrame(df[\"Noun\"], columns=[\"Noun\"])\n",
    "\n",
    "\n",
    "# Get N count from corpus \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aed26f5-6bbd-47f7-83cf-97a14ac0b4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate p(n), p(w), p(n|w)\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# First, load the dataset\n",
    "df = pd.read_csv(\"/Volumes/server/SHARED/Corpora/Universal_Dependencies/2025_InformationTheory_Project/chinese_noun_mw.csv\")\n",
    "\n",
    "# Get the total number of tokens (using Count_Pre as specified)\n",
    "total_tokens = df[\"Count_Pre\"].sum()\n",
    "\n",
    "# Calculate p(n) for each noun\n",
    "# Group by Noun and sum the Count_Pre for each noun\n",
    "noun_counts = df.groupby(\"Noun\")[\"Count_Pre\"].sum().reset_index()\n",
    "noun_counts[\"P(n)\"] = noun_counts[\"Count_Pre\"] / total_tokens\n",
    "\n",
    "# Calculate p(w) for each measure word\n",
    "# Group by MW and sum the Count_Pre for each measure word\n",
    "mw_counts = df.groupby(\"MW\")[\"Count_Pre\"].sum().reset_index()\n",
    "mw_counts[\"P(w)\"] = mw_counts[\"Count_Pre\"] / total_tokens\n",
    "\n",
    "# Create a new dataframe to store our results\n",
    "result_df = df.copy()\n",
    "\n",
    "# For each row, calculate p(n|w)\n",
    "# Get total occurrences for each measure word\n",
    "mw_totals = df.groupby(\"MW\")[\"Count_Pre\"].sum().to_dict()\n",
    "\n",
    "# Add p(n|w) to the result dataframe - handling the case where Count_Pre might be 0\n",
    "def calculate_p_n_given_w(row):\n",
    "    if mw_totals[row[\"MW\"]] == 0:\n",
    "        return 0\n",
    "    return row[\"Count_Pre\"] / mw_totals[row[\"MW\"]]\n",
    "\n",
    "result_df[\"P(n|w)\"] = result_df.apply(calculate_p_n_given_w, axis=1)\n",
    "\n",
    "# Merge with P(n) values\n",
    "result_df = result_df.merge(noun_counts[[\"Noun\", \"P(n)\"]], on=\"Noun\")\n",
    "\n",
    "# Merge with P(w) values\n",
    "result_df = result_df.merge(mw_counts[[\"MW\", \"P(w)\"]], on=\"MW\")\n",
    "\n",
    "# Select and reorder the columns for the final output\n",
    "final_df = result_df[[\"Noun\", \"MW\", \"Count_Pre\", \"P(n)\", \"P(w)\", \"P(n|w)\"]]\n",
    "\n",
    "# Save the final dataframe to CSV\n",
    "final_df.to_csv(\"/Volumes/server/SHARED/Corpora/Universal_Dependencies/2025_InformationTheory_Project/noun_mw_probabilities.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf37efff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for noun '上午' with measure word '日':\n",
      "Count of this combination: 1\n",
      "Total count of noun '上午': 1\n",
      "Total count of measure word '日': 8\n",
      "P(n): 0.000437\n",
      "P(w): 0.003495\n",
      "P(n|w): 0.125000\n"
     ]
    }
   ],
   "source": [
    "def lookup_mw_noun_stats(noun, mw, probability_df, noun_counts_df, mw_counts_df):\n",
    "    \"\"\"\n",
    "    Look up statistics for a specific noun and measure word combination.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    noun : str\n",
    "        The noun to look up\n",
    "    mw : str\n",
    "        The measure word to look up\n",
    "    probability_df : pandas.DataFrame\n",
    "        DataFrame containing the probabilities\n",
    "    noun_counts_df : pandas.DataFrame\n",
    "        DataFrame containing the noun counts\n",
    "    mw_counts_df : pandas.DataFrame\n",
    "        DataFrame containing the measure word counts\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with the count and probabilities for the noun-measure word pair\n",
    "    \"\"\"\n",
    "    # Try to find the specific noun and measure word combination\n",
    "    result = probability_df[(probability_df[\"Noun\"] == noun) & (probability_df[\"MW\"] == mw)]\n",
    "    \n",
    "    if len(result) == 0:\n",
    "        print(f\"No data found for noun '{noun}' with measure word '{mw}'\")\n",
    "        return None\n",
    "    \n",
    "    # Get total count for the noun\n",
    "    noun_total = noun_counts_df[noun_counts_df[\"Noun\"] == noun][\"Count_Pre\"].values[0]\n",
    "    \n",
    "    # Get total count for the measure word\n",
    "    mw_total = mw_counts_df[mw_counts_df[\"MW\"] == mw][\"Count_Pre\"].values[0]\n",
    "    \n",
    "    # Extract the values\n",
    "    row = result.iloc[0]\n",
    "    \n",
    "    # Create a dictionary with the statistics\n",
    "    stats = {\n",
    "        \"Noun\": noun,\n",
    "        \"Measure Word\": mw,\n",
    "        \"Count\": row[\"Count_Pre\"],\n",
    "        \"Total Noun Count\": noun_total,\n",
    "        \"Total MW Count\": mw_total,\n",
    "        \"P(n)\": row[\"P(n)\"],\n",
    "        \"P(w)\": row[\"P(w)\"],\n",
    "        \"P(n|w)\": row[\"P(n|w)\"]\n",
    "    }\n",
    "    \n",
    "    # Print the statistics in a readable format\n",
    "    print(f\"Statistics for noun '{noun}' with measure word '{mw}':\")\n",
    "    print(f\"Count of this combination: {stats['Count']}\")\n",
    "    print(f\"Total count of noun '{noun}': {stats['Total Noun Count']}\")\n",
    "    print(f\"Total count of measure word '{mw}': {stats['Total MW Count']}\")\n",
    "    print(f\"P(n): {stats['P(n)']:.6f}\")\n",
    "    print(f\"P(w): {stats['P(w)']:.6f}\")\n",
    "    print(f\"P(n|w): {stats['P(n|w)']:.6f}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "noun = \"上午\"\n",
    "mw = \"日\"\n",
    "stats = lookup_mw_noun_stats(noun, mw, final_df, noun_counts, mw_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29d2b123-ba86-426c-bde0-eb335214be6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sum of all P(n): 1.000000\n",
      "Sum of all P(w): 1.000000\n",
      "Sum of P(n|w) for MW '日': 1.000000\n",
      "Sum of P(n|w) for MW '局': 1.000000\n",
      "Sum of P(n|w) for MW '年': 1.000000\n",
      "Sum of P(n|w) for MW '月': 1.000000\n",
      "Sum of P(n|w) for MW '个': 1.000000\n",
      "\n",
      "Statistics for P(n):\n",
      "count    847.000000\n",
      "mean       0.001181\n",
      "std        0.009914\n",
      "min        0.000000\n",
      "25%        0.000437\n",
      "50%        0.000437\n",
      "75%        0.000874\n",
      "max        0.278724\n",
      "Name: P(n), dtype: float64\n",
      "\n",
      "Statistics for P(w):\n",
      "count    110.000000\n",
      "mean       0.009091\n",
      "std        0.034838\n",
      "min        0.000000\n",
      "25%        0.000437\n",
      "50%        0.001311\n",
      "75%        0.003495\n",
      "max        0.238969\n",
      "Name: P(w), dtype: float64\n",
      "\n",
      "Statistics for P(n|w):\n",
      "count    1006.000000\n",
      "mean        0.108350\n",
      "std         0.224800\n",
      "min         0.000000\n",
      "25%         0.001934\n",
      "50%         0.015504\n",
      "75%         0.090909\n",
      "max         1.000000\n",
      "Name: P(n|w), dtype: float64\n",
      "\n",
      "Mutual Information I(N;W): 3.368736 bits\n"
     ]
    }
   ],
   "source": [
    "# Verification and summary\n",
    "# Verify that p(n) sums to 1 (or very close due to floating point)\n",
    "p_n_sum = noun_counts[\"P(n)\"].sum()\n",
    "print(f\"\\nSum of all P(n): {p_n_sum:.6f}\")\n",
    "\n",
    "# Verify that p(w) sums to 1\n",
    "p_w_sum = mw_counts[\"P(w)\"].sum()\n",
    "print(f\"Sum of all P(w): {p_w_sum:.6f}\")\n",
    "\n",
    "# For each MW, verify that sum of p(n|w) = 1 for a few sample MWs\n",
    "sample_mws = final_df[\"MW\"].unique()[:5]  # Take first 5 MWs as samples\n",
    "for mw in sample_mws:\n",
    "    p_n_given_w_sum = final_df[final_df[\"MW\"] == mw][\"P(n|w)\"].sum()\n",
    "    print(f\"Sum of P(n|w) for MW '{mw}': {p_n_given_w_sum:.6f}\")\n",
    "\n",
    "# Statistics on distributions\n",
    "print(\"\\nStatistics for P(n):\")\n",
    "print(noun_counts[\"P(n)\"].describe())\n",
    "\n",
    "print(\"\\nStatistics for P(w):\")\n",
    "print(mw_counts[\"P(w)\"].describe())\n",
    "\n",
    "print(\"\\nStatistics for P(n|w):\")\n",
    "print(final_df[\"P(n|w)\"].describe())\n",
    "\n",
    "# Calculate the mutual information I(N;W)\n",
    "# Joint probability p(n,w)\n",
    "final_df[\"P(n,w)\"] = final_df[\"Count_Pre\"] / total_tokens\n",
    "\n",
    "# Log term for mutual information\n",
    "# Add small epsilon to avoid log(0)\n",
    "epsilon = 1e-10\n",
    "final_df[\"log_term\"] = np.log2((final_df[\"P(n,w)\"] + epsilon) / \n",
    "                               (final_df[\"P(n)\"] * final_df[\"P(w)\"] + epsilon))\n",
    "\n",
    "# Contribution to mutual information\n",
    "final_df[\"MI_contribution\"] = final_df[\"P(n,w)\"] * final_df[\"log_term\"]\n",
    "\n",
    "# Total mutual information\n",
    "mutual_info = final_df[\"MI_contribution\"].sum()\n",
    "print(f\"\\nMutual Information I(N;W): {mutual_info:.6f} bits\")\n",
    "\n",
    "# Save extended dataframe with MI calculations\n",
    "final_df_extended = final_df.copy()\n",
    "final_df_extended[\"P(n,w)\"] = final_df[\"P(n,w)\"]\n",
    "final_df_extended[\"MI_contribution\"] = final_df[\"MI_contribution\"]\n",
    "final_df_extended.to_csv(\"noun_mw_probabilities_with_MI.csv\", index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
