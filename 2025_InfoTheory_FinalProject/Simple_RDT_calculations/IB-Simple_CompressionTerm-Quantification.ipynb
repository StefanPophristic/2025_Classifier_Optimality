{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56ef5920-5026-4b89-9779-c12ad01dda64",
   "metadata": {},
   "source": [
    "Stefan Pophristic + Boxuan Li\n",
    "May 1st, 2025\n",
    "Information Theory Project\n",
    "\n",
    "After our Meeting with Noga on April 30th, we agreed to first try to implement a simpler information bottlneck calcuation to test whether Mandarin classifiers are optimal. \n",
    "\n",
    "The general IB Formula is:\n",
    "$$\n",
    "  min I(X;T) - \\beta I(T;Y)\n",
    "$$\n",
    "\n",
    "Noga suggested the quantify our analysis as follows:\n",
    "$$\n",
    "I_{q}(N;W) + \\beta \\mathbb{E}[d(N; N_{w})]\n",
    "$$\n",
    "\n",
    "N = the set of all Nouns to which MW can refer to\n",
    "W = the set of all MW\n",
    "\n",
    "\n",
    "**In this script we quantify the first term**\n",
    "\n",
    "**The First Term (Input Term)**\n",
    "The mutual information between N and W can be computed using the normal mutual information calculations:\n",
    "$$\n",
    "I_{q}(N;W) = \\sum_{n\\in N}\\sum_{w \\in W} p(n,w) log\\frac{p(n,w)}{p(n)p(w)}\n",
    "$$\n",
    "$$\n",
    "p(n, w) = p(n|w)p(w)\n",
    "$$\n",
    "\n",
    "p(n) = probbability of a noun in the corpus\n",
    "p(w) = probability of a MW in the corpus\n",
    "p(n|w) = probability of the noun given a MW\n",
    "\n",
    "\n",
    "**The Second Term (Output Term)**\n",
    "Also known as the reconstruction error. \n",
    "\n",
    "$N_{w}$ = The set of centroids in the semantic vector space of all nouns, grouped by MW\n",
    "\n",
    "$d$ is a function that measures the reconstruction error. It could be something like KL divergence or mean square errors. In our case, we will just use the cosine similarity (i.e. distance in semantic vector space) between an N and its associated MW. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9dbc90-e0e0-4678-b8a6-e79e8814402d",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d49d1c-5ee7-4aa1-8b94-3a6a0adc73d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For displaying Chinese characters properly\n",
    "plt.rcParams['font.family'] = ['Arial Unicode MS', 'SimHei', 'sans-serif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce64cc94-6909-4bf5-a3f0-60e082ee9f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MW and Noun combinations from the corpus\n",
    "df = pd.read_csv(\"/Volumes/Server/SHARED/Corpora/Universal_Dependencies/2025_InformationTheory_Project/chinese_noun_mw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d09397b-b7bf-4abc-8a85-1ec380e85d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Noun</th>\n",
       "      <th>MW</th>\n",
       "      <th>Count_Pre</th>\n",
       "      <th>Count_Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>上午</td>\n",
       "      <td>日</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>下半</td>\n",
       "      <td>局</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>下旬</td>\n",
       "      <td>年</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>下旬</td>\n",
       "      <td>月</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>下颌</td>\n",
       "      <td>个</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Noun MW  Count_Pre  Count_Post\n",
       "0   上午  日          1           0\n",
       "1   下半  局          1           0\n",
       "2   下旬  年          1           0\n",
       "3   下旬  月          2           0\n",
       "4   下颌  个          1           0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd8c02db-83cd-4957-b828-273a333f3dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of MW + Noun tokens: 2289\n",
      "Total number of unique MW: 110\n",
      "Total number of unique Nouns: 847\n"
     ]
    }
   ],
   "source": [
    "token_count = df[\"Count_Pre\"].sum()\n",
    "print(f\"Total number of MW + Noun tokens: {token_count}\")\n",
    "\n",
    "MW_count = df[\"MW\"].nunique()\n",
    "print(f\"Total number of unique MW: {MW_count}\")\n",
    "\n",
    "N_count = df[\"Noun\"].nunique()\n",
    "print(f\"Total number of unique Nouns: {N_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d3b669-d7d7-4104-8d7b-092ed63f6e0d",
   "metadata": {},
   "source": [
    "# Quantify Probabilities [p(n), p(w), p(n|w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9aed26f5-6bbd-47f7-83cf-97a14ac0b4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2289\n"
     ]
    }
   ],
   "source": [
    "# Calculate p(n), p(w), p(n|w)\n",
    "\n",
    "# Get the total number of tokens (using Count_Pre as specified)\n",
    "total_tokens = df[\"Count_Pre\"].sum()\n",
    "print(total_tokens)\n",
    "\n",
    "# Calculate p(n) for each noun\n",
    "# Group by Noun and sum the Count_Pre for each noun\n",
    "noun_counts = df.groupby(\"Noun\")[\"Count_Pre\"].sum().reset_index()\n",
    "noun_counts[\"P(n)\"] = noun_counts[\"Count_Pre\"] / total_tokens\n",
    "\n",
    "# Calculate p(w) for each measure word\n",
    "# Group by MW and sum the Count_Pre for each measure word\n",
    "mw_counts = df.groupby(\"MW\")[\"Count_Pre\"].sum().reset_index()\n",
    "mw_counts[\"P(w)\"] = mw_counts[\"Count_Pre\"] / total_tokens\n",
    "\n",
    "# Create a new dataframe to store our results\n",
    "result_df = df.copy()\n",
    "\n",
    "# For each row, calculate p(n|w)\n",
    "# Get total occurrences for each measure word\n",
    "mw_totals = df.groupby(\"MW\")[\"Count_Pre\"].sum().to_dict()\n",
    "\n",
    "# Add p(n|w) to the result dataframe - handling the case where Count_Pre might be 0\n",
    "def calculate_p_n_given_w(row):\n",
    "    if mw_totals[row[\"MW\"]] == 0:\n",
    "        return 0\n",
    "    return row[\"Count_Pre\"] / mw_totals[row[\"MW\"]]\n",
    "\n",
    "result_df[\"P(n|w)\"] = result_df.apply(calculate_p_n_given_w, axis=1)\n",
    "\n",
    "# Merge with P(n) values\n",
    "result_df = result_df.merge(noun_counts[[\"Noun\", \"P(n)\"]], on=\"Noun\")\n",
    "\n",
    "# Merge with P(w) values\n",
    "result_df = result_df.merge(mw_counts[[\"MW\", \"P(w)\"]], on=\"MW\")\n",
    "\n",
    "# Select and reorder the columns for the final output\n",
    "final_df = result_df[[\"Noun\", \"MW\", \"Count_Pre\", \"P(n)\", \"P(w)\", \"P(n|w)\"]]\n",
    "\n",
    "# Save the final dataframe to CSV\n",
    "# final_df.to_csv(\"/Volumes/server/SHARED/Corpora/Universal_Dependencies/2025_InformationTheory_Project/noun_mw_probabilities.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf37efff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for noun '上午' with measure word '日':\n",
      "Count of this combination: 1\n",
      "Total count of noun '上午': 1\n",
      "Total count of measure word '日': 8\n",
      "P(n): 0.000437\n",
      "P(w): 0.003495\n",
      "P(n|w): 0.125000\n"
     ]
    }
   ],
   "source": [
    "def lookup_mw_noun_stats(noun, mw, probability_df, noun_counts_df, mw_counts_df):\n",
    "    \n",
    "    # Try to find the specific noun and measure word combination\n",
    "    result = probability_df[(probability_df[\"Noun\"] == noun) & (probability_df[\"MW\"] == mw)]\n",
    "    \n",
    "    if len(result) == 0:\n",
    "        print(f\"No data found for noun '{noun}' with measure word '{mw}'\")\n",
    "        return None\n",
    "    \n",
    "    # Get total count for the noun\n",
    "    noun_total = noun_counts_df[noun_counts_df[\"Noun\"] == noun][\"Count_Pre\"].values[0]\n",
    "    \n",
    "    # Get total count for the measure word\n",
    "    mw_total = mw_counts_df[mw_counts_df[\"MW\"] == mw][\"Count_Pre\"].values[0]\n",
    "    \n",
    "    # Extract the values\n",
    "    row = result.iloc[0]\n",
    "    \n",
    "    # Create a dictionary with the statistics\n",
    "    stats = {\n",
    "        \"Noun\": noun,\n",
    "        \"Measure Word\": mw,\n",
    "        \"Count\": row[\"Count_Pre\"],\n",
    "        \"Total Noun Count\": noun_total,\n",
    "        \"Total MW Count\": mw_total,\n",
    "        \"P(n)\": row[\"P(n)\"],\n",
    "        \"P(w)\": row[\"P(w)\"],\n",
    "        \"P(n|w)\": row[\"P(n|w)\"]\n",
    "    }\n",
    "    \n",
    "    # Print the statistics in a readable format\n",
    "    print(f\"Statistics for noun '{noun}' with measure word '{mw}':\")\n",
    "    print(f\"Count of this combination: {stats['Count']}\")\n",
    "    print(f\"Total count of noun '{noun}': {stats['Total Noun Count']}\")\n",
    "    print(f\"Total count of measure word '{mw}': {stats['Total MW Count']}\")\n",
    "    print(f\"P(n): {stats['P(n)']:.6f}\")\n",
    "    print(f\"P(w): {stats['P(w)']:.6f}\")\n",
    "    print(f\"P(n|w): {stats['P(n|w)']:.6f}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "noun = \"上午\"\n",
    "mw = \"日\"\n",
    "stats = lookup_mw_noun_stats(noun, mw, final_df, noun_counts, mw_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29d2b123-ba86-426c-bde0-eb335214be6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mutual Information for first 20 noun-measure word pairs:\n",
      "Noun\tMW\tCount_pre\tMI_contribution\n",
      "上午\t日\t1\t0.003565\n",
      "下半\t局\t1\t0.004875\n",
      "下旬\t年\t1\t0.000245\n",
      "下旬\t月\t2\t0.001776\n",
      "下颌\t个\t1\t0.000902\n",
      "专辑\t张\t6\t0.019274\n",
      "世纪\t个\t4\t0.003609\n",
      "东征\t次\t2\t0.004414\n",
      "个\t个\t0\t0.000000\n",
      "中叶\t世纪\t1\t0.003090\n",
      "中学\t个\t1\t0.000210\n",
      "中学\t所\t2\t0.005403\n",
      "中心\t个\t1\t0.000210\n",
      "中心\t处\t1\t0.004183\n",
      "中心\t间\t1\t0.002476\n",
      "中旬\t年\t1\t0.000245\n",
      "中旬\t月\t2\t0.001776\n",
      "中期\t年代\t5\t0.016548\n",
      "中药\t种\t1\t0.001813\n",
      "主张\t项\t1\t0.003054\n",
      "\n",
      "Mutual Information I(N;W): 3.368736 bits\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mutual information I(N;W)\n",
    "# Joint probability p(n,w)\n",
    "final_df[\"P(n,w)\"] = final_df[\"Count_Pre\"] / total_tokens\n",
    "\n",
    "# Log term for mutual information\n",
    "# Add small epsilon to avoid log(0)\n",
    "epsilon = 1e-10\n",
    "final_df[\"log_term\"] = np.log2((final_df[\"P(n,w)\"] + epsilon) / \n",
    "                               (final_df[\"P(n)\"] * final_df[\"P(w)\"] + epsilon))\n",
    "\n",
    "# Contribution to mutual information\n",
    "final_df[\"MI_contribution\"] = final_df[\"P(n,w)\"] * final_df[\"log_term\"]\n",
    "\n",
    "# Print mutual information for the first 20 pairs\n",
    "print(\"\\nMutual Information for first 20 noun-measure word pairs:\")\n",
    "print(\"Noun\\tMW\\tCount_pre\\tMI_contribution\")\n",
    "for i in range(min(20, len(final_df))):\n",
    "    row = final_df.iloc[i]\n",
    "    print(f\"{row['Noun']}\\t{row['MW']}\\t{row['Count_Pre']}\\t{row['MI_contribution']:.6f}\")\n",
    "\n",
    "# Total mutual information\n",
    "mutual_info = final_df[\"MI_contribution\"].sum()\n",
    "print(f\"\\nMutual Information I(N;W): {mutual_info:.6f} bits\")\n",
    "\n",
    "# Save extended dataframe with MI calculations\n",
    "final_df_extended = final_df.copy()\n",
    "final_df_extended[\"P(n,w)\"] = final_df[\"P(n,w)\"]\n",
    "final_df_extended[\"MI_contribution\"] = final_df[\"MI_contribution\"]\n",
    "final_df_extended.to_csv(\"/Volumes/Server/SHARED/Corpora/Universal_Dependencies/2025_InformationTheory_Project/noun_mw_probabilities_with_MI.csv\", index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eegmeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
